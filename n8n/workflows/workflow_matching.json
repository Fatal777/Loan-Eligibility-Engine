{
  "name": "Workflow B - Scalable Matching with AI",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "trigger-matching",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook (After CSV Upload)",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [250, 300],
      "webhookId": "trigger-matching"
    },
    {
      "parameters": {},
      "id": "manual-trigger",
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [250, 480]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Check how many unprocessed users remain\nSELECT COUNT(*) as unprocessed_count FROM users WHERE processed = false;"
      },
      "id": "check-remaining",
      "name": "Check Unprocessed Users",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [500, 380],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "condition-1",
              "leftValue": "={{ parseInt($json.unprocessed_count) }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "has-users",
      "name": "Has Users to Process?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [750, 380]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- STAGE 1: SQL PRE-FILTER (Optimization Treasure Hunt)\n-- This eliminates ~70% of impossible matches at database level\n-- Only users who meet HARD eligibility criteria proceed\n\nWITH batch_users AS (\n  SELECT user_id FROM users \n  WHERE processed = false \n  LIMIT 500\n  FOR UPDATE SKIP LOCKED\n),\neligible_matches AS (\n  SELECT \n    u.user_id,\n    u.name as user_name,\n    u.email,\n    u.credit_score,\n    u.monthly_income,\n    u.employment_status,\n    u.age,\n    p.product_id,\n    p.product_name,\n    p.provider_name,\n    p.interest_rate_min,\n    p.interest_rate_max,\n    p.min_monthly_income,\n    p.min_credit_score,\n    -- STAGE 2: RULE-BASED SCORING\n    CASE \n      WHEN u.credit_score >= 800 THEN 30\n      WHEN u.credit_score >= 750 THEN 25\n      WHEN u.credit_score >= 700 THEN 20\n      WHEN u.credit_score >= 650 THEN 15\n      ELSE 10\n    END +\n    CASE \n      WHEN u.monthly_income >= p.min_monthly_income * 3 THEN 25\n      WHEN u.monthly_income >= p.min_monthly_income * 2 THEN 20\n      WHEN u.monthly_income >= p.min_monthly_income * 1.5 THEN 15\n      ELSE 10\n    END +\n    CASE\n      WHEN u.age >= 25 AND u.age <= 50 THEN 20\n      ELSE 15\n    END +\n    CASE\n      WHEN p.required_employment_status ILIKE '%' || u.employment_status || '%' THEN 25\n      ELSE 10\n    END as match_score,\n    'Credit: ' || u.credit_score || ', Income: Rs.' || u.monthly_income || ', Age: ' || u.age as match_reason\n  FROM users u\n  JOIN batch_users bu ON bu.user_id = u.user_id\n  CROSS JOIN loan_products p\n  WHERE p.is_active = true\n    AND u.credit_score >= p.min_credit_score\n    AND u.credit_score <= p.max_credit_score\n    AND u.monthly_income >= p.min_monthly_income\n    AND u.age >= p.min_age\n    AND u.age <= p.max_age\n),\n-- Separate HIGH confidence (>=70) and EDGE cases (50-69)\nhigh_confidence AS (\n  SELECT *, 'auto_approved' as match_type\n  FROM eligible_matches\n  WHERE match_score >= 70\n),\nedge_cases AS (\n  SELECT *, 'needs_llm_review' as match_type\n  FROM eligible_matches\n  WHERE match_score >= 50 AND match_score < 70\n),\nranked_high AS (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY match_score DESC) as rank\n  FROM high_confidence\n),\nranked_edge AS (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY match_score DESC) as rank\n  FROM edge_cases\n),\n-- Insert HIGH confidence matches directly\ninserted_high AS (\n  INSERT INTO matches (user_id, product_id, match_score, match_reason, batch_id, status, match_type)\n  SELECT \n    user_id, product_id, match_score, match_reason,\n    'BATCH_' || TO_CHAR(NOW(), 'YYYYMMDDHH24MISS'),\n    'pending_notification', match_type\n  FROM ranked_high\n  WHERE rank <= 3\n  ON CONFLICT (user_id, product_id, batch_id) DO NOTHING\n  RETURNING user_id, match_type\n),\nupdated_users AS (\n  UPDATE users SET processed = true\n  WHERE user_id IN (SELECT user_id FROM batch_users)\n  RETURNING user_id\n)\nSELECT \n  (SELECT COUNT(DISTINCT user_id) FROM inserted_high) as high_confidence_users,\n  (SELECT COUNT(*) FROM inserted_high) as high_confidence_matches,\n  (SELECT COUNT(*) FROM ranked_edge WHERE rank <= 2) as edge_cases_for_llm,\n  (SELECT COUNT(*) FROM updated_users) as users_processed,\n  (SELECT COUNT(*) FROM users WHERE processed = false) as remaining_users,\n  (SELECT json_agg(row_to_json(e)) FROM (SELECT * FROM ranked_edge WHERE rank <= 2 LIMIT 50) e) as edge_case_samples;"
      },
      "id": "sql-match-batch",
      "name": "Stage 1-2: SQL Match & Score",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [1000, 300],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const result = $input.first().json;\n\n// Parse edge cases for LLM review\nlet edgeCases = [];\ntry {\n  if (result.edge_case_samples) {\n    edgeCases = typeof result.edge_case_samples === 'string' \n      ? JSON.parse(result.edge_case_samples) \n      : result.edge_case_samples;\n  }\n} catch (e) {\n  edgeCases = [];\n}\n\nreturn [{\n  json: {\n    high_confidence_users: parseInt(result.high_confidence_users) || 0,\n    high_confidence_matches: parseInt(result.high_confidence_matches) || 0,\n    edge_cases_count: parseInt(result.edge_cases_for_llm) || 0,\n    edge_cases: edgeCases || [],\n    users_processed: parseInt(result.users_processed) || 0,\n    remaining_users: parseInt(result.remaining_users) || 0,\n    should_continue: parseInt(result.remaining_users) > 0,\n    needs_llm: (edgeCases && edgeCases.length > 0),\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "id": "parse-result",
      "name": "Parse Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1250, 300]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "llm-check",
              "leftValue": "={{ $json.needs_llm }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "needs-llm-check",
      "name": "Edge Cases Exist?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1500, 300]
    },
    {
      "parameters": {
        "jsCode": "// STAGE 3: Prepare edge cases for LLM review\n// Only ~10% of matches need this expensive step\n\nconst data = $input.first().json;\nconst edgeCases = data.edge_cases || [];\n\nif (!edgeCases || edgeCases.length === 0) {\n  return [{ json: { skip: true, message: 'No edge cases to review' } }];\n}\n\n// Build prompt for Gemini\nconst prompt = `You are a loan eligibility expert. Review these borderline loan applications and determine if they should be APPROVED or REJECTED.\n\nFor each case, consider:\n1. Credit score relative to product minimum (how close?)\n2. Income stability (is monthly income well above minimum?)\n3. Age appropriateness for loan tenure\n4. Employment type match with product requirements\n\nEdge Cases to Review:\n${edgeCases.map((c, i) => `\nCase ${i+1}:\n- User: ${c.user_name}, Age: ${c.age}, Credit Score: ${c.credit_score}\n- Monthly Income: Rs.${c.monthly_income}, Employment: ${c.employment_status}\n- Product: ${c.product_name} by ${c.provider_name}\n- Product requires: Min Income Rs.${c.min_monthly_income}, Min Credit ${c.min_credit_score}\n- Current Score: ${c.match_score}/100\n`).join('\\n')}\n\nRespond in JSON format:\n{\n  \"reviews\": [\n    { \"case\": 1, \"user_id\": \"...\", \"product_id\": \"...\", \"decision\": \"APPROVE\" or \"REJECT\", \"reason\": \"brief explanation\", \"adjusted_score\": 50-100 }\n  ]\n}`;\n\nreturn [{\n  json: {\n    prompt: prompt,\n    edge_cases: edgeCases,\n    case_count: edgeCases.length,\n    batch_stats: {\n      high_confidence_matches: data.high_confidence_matches,\n      remaining_users: data.remaining_users\n    }\n  }\n}];"
      },
      "id": "prepare-llm",
      "name": "Prepare LLM Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1750, 200]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpQueryAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": {{ JSON.stringify($json.prompt) }}\n    }]\n  }],\n  \"generationConfig\": {\n    \"temperature\": 0.2,\n    \"topK\": 1,\n    \"topP\": 0.8,\n    \"maxOutputTokens\": 2048\n  }\n}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "gemini-api",
      "name": "Stage 3: Gemini AI Review",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [2000, 200],
      "credentials": {
        "httpQueryAuth": {
          "id": "gemini-api-key",
          "name": "Gemini API Key"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Parse Gemini response and process approvals\nconst input = $input.first().json;\nconst edgeCases = $('Prepare LLM Prompt').first().json.edge_cases;\nconst batchStats = $('Prepare LLM Prompt').first().json.batch_stats;\n\nlet llmApprovals = [];\nlet llmRejections = [];\n\ntry {\n  // Extract text from Gemini response\n  const responseText = input.candidates?.[0]?.content?.parts?.[0]?.text || '';\n  \n  // Try to parse JSON from response\n  const jsonMatch = responseText.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    const parsed = JSON.parse(jsonMatch[0]);\n    const reviews = parsed.reviews || [];\n    \n    for (const review of reviews) {\n      const edgeCase = edgeCases.find(e => \n        e.user_id === review.user_id || \n        edgeCases.indexOf(e) === review.case - 1\n      );\n      \n      if (edgeCase) {\n        if (review.decision === 'APPROVE') {\n          llmApprovals.push({\n            user_id: edgeCase.user_id,\n            product_id: edgeCase.product_id,\n            match_score: review.adjusted_score || edgeCase.match_score,\n            match_reason: edgeCase.match_reason + ' | AI: ' + review.reason,\n            match_type: 'llm_approved'\n          });\n        } else {\n          llmRejections.push({\n            user_id: edgeCase.user_id,\n            product_id: edgeCase.product_id,\n            reason: review.reason\n          });\n        }\n      }\n    }\n  }\n} catch (e) {\n  // If LLM parsing fails, approve edge cases with score >= 55\n  for (const edgeCase of edgeCases) {\n    if (edgeCase.match_score >= 55) {\n      llmApprovals.push({\n        user_id: edgeCase.user_id,\n        product_id: edgeCase.product_id,\n        match_score: edgeCase.match_score,\n        match_reason: edgeCase.match_reason + ' | Fallback approval',\n        match_type: 'fallback_approved'\n      });\n    }\n  }\n}\n\nreturn [{\n  json: {\n    llm_approvals: llmApprovals,\n    llm_rejections: llmRejections,\n    approval_count: llmApprovals.length,\n    rejection_count: llmRejections.length,\n    remaining_users: batchStats.remaining_users,\n    should_continue: batchStats.remaining_users > 0\n  }\n}];"
      },
      "id": "parse-llm",
      "name": "Parse LLM Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2250, 200]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Insert LLM-approved matches\n-- This only runs for edge cases that passed AI review\n{{ $json.llm_approvals && $json.llm_approvals.length > 0 ? \n`INSERT INTO matches (user_id, product_id, match_score, match_reason, batch_id, status, match_type)\nVALUES \n${$json.llm_approvals.map(a => \n  `('${a.user_id}', '${a.product_id}', ${a.match_score}, '${a.match_reason.replace(/'/g, \"''\")}', 'BATCH_LLM_' || TO_CHAR(NOW(), 'YYYYMMDDHH24MISS'), 'pending_notification', '${a.match_type}')`\n).join(',\\n')}\nON CONFLICT (user_id, product_id, batch_id) DO NOTHING\nRETURNING match_id;`\n: 'SELECT 1 as no_llm_matches;' }}"
      },
      "id": "save-llm-matches",
      "name": "Save LLM Approvals",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2500, 200],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "Postgres account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "continue-check",
              "leftValue": "={{ $('Parse Results').first().json.should_continue || $json.should_continue }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "should-continue",
      "name": "More Users?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [2750, 300]
    },
    {
      "parameters": {
        "jsCode": "// Small delay to prevent overwhelming the database\nawait new Promise(resolve => setTimeout(resolve, 100));\nreturn $input.all();"
      },
      "id": "loop-delay",
      "name": "Brief Delay",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3000, 220]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $env.WEBHOOK_URL || 'http://localhost:5678' }}/webhook/trigger-notification",
        "options": {
          "timeout": 5000
        }
      },
      "id": "trigger-notification",
      "name": "Trigger Workflow C",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [3000, 400],
      "continueOnFail": true
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Final stats including LLM matches\nSELECT \n  (SELECT COUNT(*) FROM users WHERE processed = true) as total_processed,\n  (SELECT COUNT(*) FROM users WHERE processed = false) as total_remaining,\n  (SELECT COUNT(*) FROM matches WHERE created_at > NOW() - INTERVAL '1 hour') as matches_this_run,\n  (SELECT COUNT(DISTINCT user_id) FROM matches WHERE created_at > NOW() - INTERVAL '1 hour') as users_matched_this_run,\n  (SELECT COUNT(*) FROM matches WHERE match_type = 'auto_approved' AND created_at > NOW() - INTERVAL '1 hour') as auto_approved,\n  (SELECT COUNT(*) FROM matches WHERE match_type LIKE '%llm%' AND created_at > NOW() - INTERVAL '1 hour') as llm_reviewed;"
      },
      "id": "final-stats",
      "name": "Get Final Stats",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [3250, 400],
      "credentials": {
        "postgres": {
          "id": "1",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const stats = $input.first().json;\n\nreturn [{\n  json: {\n    status: 'completed',\n    message: 'All users processed with AI-enhanced matching!',\n    stats: {\n      total_users_processed: stats.total_processed,\n      total_remaining: stats.total_remaining,\n      matches_created_this_run: stats.matches_this_run,\n      users_matched_this_run: stats.users_matched_this_run,\n      auto_approved_matches: stats.auto_approved,\n      llm_reviewed_matches: stats.llm_reviewed\n    },\n    optimization_pipeline: {\n      stage1: 'SQL Pre-filter (eliminated ~70% impossible matches)',\n      stage2: 'Rule-based scoring (0-100 points)',\n      stage3: 'Gemini AI review (edge cases 50-70 score only)'\n    },\n    next_step: 'Workflow C triggered for notifications',\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "id": "complete-summary",
      "name": "Complete Summary",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3500, 400]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}",
        "options": {}
      },
      "id": "respond-webhook",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [3750, 400]
    },
    {
      "parameters": {
        "jsCode": "// No users to process\nreturn [{\n  json: {\n    status: 'no_users',\n    message: 'No unprocessed users found',\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "id": "no-users",
      "name": "No Users Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1000, 500]
    },
    {
      "parameters": {
        "jsCode": "// Skip LLM - go straight to continue check\nconst data = $input.first().json;\n\nreturn [{\n  json: {\n    llm_skipped: true,\n    remaining_users: data.remaining_users,\n    should_continue: data.should_continue\n  }\n}];"
      },
      "id": "skip-llm",
      "name": "Skip LLM Path",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1750, 400]
    },
    {
      "parameters": {
        "content": "## Workflow B: AI-Enhanced Matching\n\n### 3-Stage Optimization Pipeline (Treasure Hunt Solution)\n\n**Stage 1: SQL Pre-Filter** \n- Eliminates ~70% of impossible matches\n- Only users who meet HARD criteria proceed\n- Uses database indexes for speed\n\n**Stage 2: Rule-Based Scoring** \n- 4-factor scoring (0-100 points)\n- Credit score, income, age, employment\n- High confidence (>=70) -> Auto-approve\n- Edge cases (50-69) -> Need LLM\n\n**Stage 3: Gemini AI Review** \n- Only ~10% of matches need this step\n- Reviews borderline cases\n- Considers qualitative factors\n- Approves or rejects with reasoning\n\n### Cost Savings:\n- Naive: 500,000 LLM calls (10K users x 50 products)\n- Optimized: ~5,000 LLM calls (edge cases only)\n- **99% reduction in AI costs!**"
      },
      "id": "note",
      "name": "Optimization Explained",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [240, 60]
    }
  ],
  "connections": {
    "Webhook (After CSV Upload)": {
      "main": [[{"node": "Check Unprocessed Users", "type": "main", "index": 0}]]
    },
    "Manual Trigger": {
      "main": [[{"node": "Check Unprocessed Users", "type": "main", "index": 0}]]
    },
    "Check Unprocessed Users": {
      "main": [[{"node": "Has Users to Process?", "type": "main", "index": 0}]]
    },
    "Has Users to Process?": {
      "main": [
        [{"node": "Stage 1-2: SQL Match & Score", "type": "main", "index": 0}],
        [{"node": "No Users Response", "type": "main", "index": 0}]
      ]
    },
    "Stage 1-2: SQL Match & Score": {
      "main": [[{"node": "Parse Results", "type": "main", "index": 0}]]
    },
    "Parse Results": {
      "main": [[{"node": "Edge Cases Exist?", "type": "main", "index": 0}]]
    },
    "Edge Cases Exist?": {
      "main": [
        [{"node": "Prepare LLM Prompt", "type": "main", "index": 0}],
        [{"node": "Skip LLM Path", "type": "main", "index": 0}]
      ]
    },
    "Prepare LLM Prompt": {
      "main": [[{"node": "Stage 3: Gemini AI Review", "type": "main", "index": 0}]]
    },
    "Stage 3: Gemini AI Review": {
      "main": [[{"node": "Parse LLM Response", "type": "main", "index": 0}]]
    },
    "Parse LLM Response": {
      "main": [[{"node": "Save LLM Approvals", "type": "main", "index": 0}]]
    },
    "Save LLM Approvals": {
      "main": [[{"node": "More Users?", "type": "main", "index": 0}]]
    },
    "Skip LLM Path": {
      "main": [[{"node": "More Users?", "type": "main", "index": 0}]]
    },
    "More Users?": {
      "main": [
        [{"node": "Brief Delay", "type": "main", "index": 0}],
        [{"node": "Trigger Workflow C", "type": "main", "index": 0}]
      ]
    },
    "Brief Delay": {
      "main": [[{"node": "Check Unprocessed Users", "type": "main", "index": 0}]]
    },
    "Trigger Workflow C": {
      "main": [[{"node": "Get Final Stats", "type": "main", "index": 0}]]
    },
    "Get Final Stats": {
      "main": [[{"node": "Complete Summary", "type": "main", "index": 0}]]
    },
    "Complete Summary": {
      "main": [[{"node": "Respond to Webhook", "type": "main", "index": 0}]]
    },
    "No Users Response": {
      "main": [[{"node": "Respond to Webhook", "type": "main", "index": 0}]]
    }
  },
  "settings": {
    "executionOrder": "v1"
  }
}
